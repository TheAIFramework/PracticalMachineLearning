{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a55a0b1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the class of machine learning approaches that are based on tree-like decision makers, many improved algorithms have been developed over the past two decades. We will go through three noteworthy designs that build on the idea of ensembles. The general idea is to train multiple models and combine them in various ways to improve performance.\n",
    "\n",
    "There are two primary ways of doing this when it comes to decision trees. The first is to average the output of multiple trees which limits the variance of the output given the central limit theorem. The second way is to build trees in sequence and use the output of each one to reduce the bias in the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d2f04",
   "metadata": {},
   "source": [
    "# Bagging Regressor\n",
    "\n",
    "A Bagging model works by dividing a dataset, training one tree per subset, and averaging the results. There are variants of the Bagging approach with distinct names determined by how the data is divided (i.e. Pasting, Bagging, Random Subspaces, Random Patches, etc...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "803fa10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import fetch_rcv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cdaf6503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _rcv1_dataset:\n",
      "\n",
      "RCV1 dataset\n",
      "------------\n",
      "\n",
      "Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually \n",
      "categorized newswire stories made available by Reuters, Ltd. for research \n",
      "purposes. The dataset is extensively described in [1]_.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    ==============     =====================\n",
      "    Classes                              103\n",
      "    Samples total                     804414\n",
      "    Dimensionality                     47236\n",
      "    Features           real, between 0 and 1\n",
      "    ==============     =====================\n",
      "\n",
      ":func:`sklearn.datasets.fetch_rcv1` will load the following \n",
      "version: RCV1-v2, vectors, full sets, topics multilabels::\n",
      "\n",
      "    >>> from sklearn.datasets import fetch_rcv1\n",
      "    >>> rcv1 = fetch_rcv1()\n",
      "\n",
      "It returns a dictionary-like object, with the following attributes:\n",
      "\n",
      "``data``:\n",
      "The feature matrix is a scipy CSR sparse matrix, with 804414 samples and\n",
      "47236 features. Non-zero values contains cosine-normalized, log TF-IDF vectors.\n",
      "A nearly chronological split is proposed in [1]_: The first 23149 samples are\n",
      "the training set. The last 781265 samples are the testing set. This follows \n",
      "the official LYRL2004 chronological split. The array has 0.16% of non zero \n",
      "values::\n",
      "\n",
      "    >>> rcv1.data.shape\n",
      "    (804414, 47236)\n",
      "\n",
      "``target``:\n",
      "The target values are stored in a scipy CSR sparse matrix, with 804414 samples \n",
      "and 103 categories. Each sample has a value of 1 in its categories, and 0 in \n",
      "others. The array has 3.15% of non zero values::\n",
      "\n",
      "    >>> rcv1.target.shape\n",
      "    (804414, 103)\n",
      "\n",
      "``sample_id``:\n",
      "Each sample can be identified by its ID, ranging (with gaps) from 2286 \n",
      "to 810596::\n",
      "\n",
      "    >>> rcv1.sample_id[:3]\n",
      "    array([2286, 2287, 2288], dtype=uint32)\n",
      "\n",
      "``target_names``:\n",
      "The target values are the topics of each sample. Each sample belongs to at \n",
      "least one topic, and to up to 17 topics. There are 103 topics, each \n",
      "represented by a string. Their corpus frequencies span five orders of \n",
      "magnitude, from 5 occurrences for 'GMIL', to 381327 for 'CCAT'::\n",
      "\n",
      "    >>> rcv1.target_names[:3].tolist()  # doctest: +SKIP\n",
      "    ['E11', 'ECAT', 'M11']\n",
      "\n",
      "The dataset will be downloaded from the `rcv1 homepage`_ if necessary.\n",
      "The compressed size is about 656 MB.\n",
      "\n",
      ".. _rcv1 homepage: http://jmlr.csail.mit.edu/papers/volume5/lewis04a/\n",
      "\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    .. [1] Lewis, D. D., Yang, Y., Rose, T. G., & Li, F. (2004). \n",
      "           RCV1: A new benchmark collection for text categorization research. \n",
      "           The Journal of Machine Learning Research, 5, 361-397.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RCV1 is a moderately complex \"real world\" dataset\n",
    "# it might take a minute to download the dataset\n",
    "\n",
    "rcv1 = fetch_rcv1()\n",
    "print(rcv1.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d4454e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values are normalized so we don't have to worry about that\n",
    "# convention has it that the training set should be very small compared to the test set \n",
    "\n",
    "x, xt, y, yt = train_test_split(rcv1.data, rcv1.target, test_size = 0.971)\n",
    "\n",
    "x, xt, y, yt = x.toarray(), xt[0:20000].toarray(), y.toarray(), yt[0:20000].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "98d2c0cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1369"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that datasets are bigger, training takes longer\n",
    "# this should take about 2 minutes on a modern CPU \n",
    "\n",
    "m = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "m.fit(x, y)\n",
    "\n",
    "ŷ = m.predict(xt)\n",
    "accuracy_score(yt, ŷ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c837c218",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (23328, 103) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [188]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# we are training the same tree but using bagging\u001b[39;00m\n\u001b[0;32m      3\u001b[0m mb \u001b[38;5;241m=\u001b[39m BaggingClassifier(DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m), \n\u001b[0;32m      4\u001b[0m                        n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      5\u001b[0m                        verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:269\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[0;32m    261\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[0;32m    263\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    268\u001b[0m )\n\u001b[1;32m--> 269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:313\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    311\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples \u001b[38;5;241m=\u001b[39m n_samples\n\u001b[1;32m--> 313\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# Check parameters\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_estimator()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719\u001b[0m, in \u001b[0;36mBaggingClassifier._validate_y\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m--> 719\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    720\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1038\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1030\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1031\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1035\u001b[0m         )\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[1;32m-> 1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1040\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (23328, 103) instead."
     ]
    }
   ],
   "source": [
    "# we are training the same tree but using bagging\n",
    "\n",
    "mb = BaggingClassifier(DecisionTreeClassifier(max_depth=5, min_samples_leaf=5), \n",
    "                       n_estimators=10,\n",
    "                       verbose=1)\n",
    "\n",
    "mb.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "565c57ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3],\n",
       " [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = np.mean([tree.feature_importances_ for tree in m.estimators_], axis=0)\n",
    "\n",
    "# visualize the points\n",
    "# log_e scale the importance\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(rcv1.feature_names, np.exp(fi))\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5c6934cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can visualize the accuracy of the model using a confusion matrix\n",
    "\n",
    "acc = confusion_matrix(yt, ŷ)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(acc, cmap='bwr')\n",
    "ax.xaxis.set(ticks=(0, 1, 2), ticklabels=('Setosa', 'Versicolor', 'Virginica'))\n",
    "ax.yaxis.set(ticks=(0, 1, 2), ticklabels=('Setosa', 'Versicolor', 'Virginica'))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax.text(j, i, acc[i][j], color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30e030",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "In random forests (see RandomForestClassifier and RandomForestRegressor classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set.\n",
    "\n",
    "Furthermore, when splitting each node during the construction of a tree, the best split is found either from all input features or a random subset of size max_features. (See the parameter tuning guidelines for more details).\n",
    "\n",
    "The purpose of these two sources of randomness is to decrease the variance of the forest estimator. Indeed, individual decision trees typically exhibit high variance and tend to overfit. The injected randomness in forests yield decision trees with somewhat decoupled prediction errors. By taking an average of those predictions, some errors can cancel out. Random forests achieve a reduced variance by combining diverse trees, sometimes at the cost of a slight increase in bias. In practice the variance reduction is often significant hence yielding an overall better model.\n",
    "\n",
    "In contrast to the original publication [B2001], the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8af023",
   "metadata": {},
   "source": [
    "The main parameters to adjust when using these methods is n_estimators and max_features. The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees. The latter is the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias. Empirical good default values are max_features=None (always considering all features instead of a random subset) for regression problems, and max_features=\"sqrt\" (using a random subset of size sqrt(n_features)) for classification tasks (where n_features is the number of features in the data). Good results are often achieved when setting max_depth=None in combination with min_samples_split=2 (i.e., when fully developing the trees). Bear in mind though that these values are usually not optimal, and might result in models that consume a lot of RAM. The best parameter values should always be cross-validated. In addition, note that in random forests, bootstrap samples are used by default (bootstrap=True) while the default strategy for extra-trees is to use the whole dataset (bootstrap=False). When using bootstrap sampling the generalization accuracy can be estimated on the left out or out-of-bag samples. This can be enabled by setting oob_score=True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15951c74",
   "metadata": {},
   "source": [
    "Finally, this module also features the parallel construction of the trees and the parallel computation of the predictions through the n_jobs parameter. If n_jobs=k then computations are partitioned into k jobs, and run on k cores of the machine. If n_jobs=-1 then all cores available on the machine are used. Note that because of inter-process communication overhead, the speedup might not be linear (i.e., using k jobs will unfortunately not be k times as fast). Significant speedup can still be achieved though when building a large number of trees, or when building a single tree requires a fair amount of time (e.g., on large datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b80e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88eb9235",
   "metadata": {},
   "source": [
    "# Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259aa1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b32ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5ad1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
